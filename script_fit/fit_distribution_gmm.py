import argparse
import logging
import numpy as np
import pandas as pd
import scipy.stats as st
from pathlib import Path
from scipy.stats import kstest, norm
from sklearn.mixture import GaussianMixture
from typing import Dict, Any, List, Tuple, Optional
import warnings

# ê²½ê³  ë©”ì‹œì§€ í•„í„°ë§ (ë¶ˆí•„ìš”í•œ RuntimeWarning ìˆ¨ê¹€)
warnings.filterwarnings('ignore')

# -----------------------------------------------------------------------------
# ë¡œê¹… ì„¤ì •
# -----------------------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="[%(levelname)s] %(message)s"
)
logger = logging.getLogger(__name__)


# -----------------------------------------------------------------------------
# 1. ë°ì´í„° ìœ í‹¸ë¦¬í‹° & ì ìˆ˜ ê³„ì‚° (Data Utils & Scoring)
# -----------------------------------------------------------------------------

def ensure_positive(x: np.ndarray, eps: float = 1e-9) -> np.ndarray:
    """ë°ì´í„° ì–‘ìˆ˜ ë³´ì • (ë¡œê·¸ ë¶„í¬ í”¼íŒ… ì‹œ ì—ëŸ¬ ë°©ì§€)"""
    x = np.asarray(x, dtype=float)
    x = x[x >= 0]
    return np.maximum(x, eps)

def calculate_fitting_score(data: np.ndarray, dist_name: str, params: tuple) -> float:
    """
    [í•µì‹¬ ê¸°ëŠ¥] ëª¨ë¸ ì í•©ë„ ì ìˆ˜ ê³„ì‚° (R-squared of CDF)
    
    * ì„¤ëª…: sklearn.metrics.r2_scoreì™€ ìˆ˜í•™ì ìœ¼ë¡œ ë™ì¼í•œ ë¡œì§ì…ë‹ˆë‹¤.
    * ë¦¬í„´: 0 ~ 100 ì‚¬ì´ì˜ ì ìˆ˜ (100ì ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì™„ë²½í•˜ê²Œ ì¼ì¹˜í•¨)
    """
    n = len(data)
    if n < 2: return 0.0
    
    # 1. Empirical CDF (ì‹¤ì œ ë°ì´í„°ì˜ ë¶„í¬)
    # ë°ì´í„°ë¥¼ ì •ë ¬í•˜ì—¬ ê° í¬ì¸íŠ¸ê°€ ì „ì²´ì˜ ëª‡ % ìœ„ì¹˜ì— ìˆëŠ”ì§€ ê³„ì‚°
    x_sorted = np.sort(data)
    y_empirical = np.arange(1, n + 1) / n
    
    # 2. Theoretical CDF (ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ë¶„í¬)
    # ê°™ì€ ë°ì´í„° ê°’(x)ì„ ë„£ì—ˆì„ ë•Œ ëª¨ë¸ì€ ëª‡ % ìœ„ì¹˜ë¼ê³  ì˜ˆì¸¡í•˜ëŠ”ì§€ ê³„ì‚°
    dist = getattr(st, dist_name)
    y_theoretical = dist.cdf(x_sorted, *params)
    
    # 3. R-squared ê³„ì‚° (1 - ì”ì°¨ì œê³±í•© / ì´ì œê³±í•©)
    ss_res = np.sum((y_empirical - y_theoretical) ** 2)
    ss_tot = np.sum((y_empirical - np.mean(y_empirical)) ** 2)
    
    if ss_tot == 0: return 0.0
    
    r2 = 1 - (ss_res / ss_tot)
    
    # ìŒìˆ˜ê°€ ë‚˜ì˜¤ë©´(ëª¨ë¸ì´ í‰ê· ë³´ë‹¤ ëª»í•˜ë©´) 0ì ìœ¼ë¡œ ì²˜ë¦¬, ë°±ë¶„ìœ¨ ë³€í™˜
    final_score = max(r2, 0.0) * 100.0
    return final_score


# -----------------------------------------------------------------------------
# 2. ë°ì´í„° ì¶”ì¶œ ë° ê³„ì‚° ë¡œì§ (SSTable Gap / Key Density)
# -----------------------------------------------------------------------------

def compute_level_gaps(level_df: pd.DataFrame) -> np.ndarray:
    """SSTable ê°„ Gap ê³„ì‚°"""
    sub = level_df.copy()
    sub["min_key"] = pd.to_numeric(sub.get("min_key"), errors="coerce")
    sub["max_key"] = pd.to_numeric(sub.get("max_key"), errors="coerce")
    
    sub = sub.dropna(subset=["min_key", "max_key"])
    if len(sub) < 2: return np.asarray([], dtype=float)

    sub = sub.sort_values(["min_key", "max_key"], kind="mergesort")
    prev_max = sub["max_key"].to_numpy(dtype=float)[:-1]
    next_min = sub["min_key"].to_numpy(dtype=float)[1:]
    
    gaps = next_min - prev_max
    return np.maximum(gaps, 0.0)


def compute_key_density(level_df: pd.DataFrame) -> np.ndarray:
    """SSTable Key Density ê³„ì‚°"""
    sub = level_df.copy()
    cols = ["min_key", "max_key", "entry_n"]
    for c in cols:
        sub[c] = pd.to_numeric(sub.get(c), errors="coerce")

    sub = sub.dropna(subset=cols)
    sub = sub[sub["entry_n"] > 0] 
    
    if len(sub) == 0: return np.asarray([], dtype=float)

    key_range = (sub["max_key"].to_numpy(dtype=float) - sub["min_key"].to_numpy(dtype=float) + 1.0)
    entry_n = sub["entry_n"].to_numpy(dtype=float)

    kd = key_range / entry_n
    
    kd = kd[np.isfinite(kd)]
    kd = kd[kd >= 0]
    return kd.astype(float, copy=False)


def compute_entry_counts(level_df: pd.DataFrame) -> np.ndarray:
    """SSTable Entry Count ì¶”ì¶œ (ë‹¨ìˆœ entry_n ì»¬ëŸ¼ ê°’)"""
    vals = pd.to_numeric(level_df.get("entry_n"), errors="coerce").dropna().to_numpy()
    return vals[vals > 0]


def build_samples_from_dir(input_dir: str, pattern: str, target_mode: str) -> pd.DataFrame:
    """CSV íŒŒì¼ë“¤ë¡œë¶€í„° ë¶„ì„ ëŒ€ìƒ ë°ì´í„° ì¶”ì¶œ"""
    in_dir = Path(input_dir)
    files = sorted(in_dir.glob(pattern))
    if not files: raise ValueError(f"íŒŒì¼ ì—†ìŒ: {in_dir}/{pattern}")

    logger.info(f"Target Mode: {target_mode.upper()}")
    logger.info(f"{len(files)}ê°œì˜ íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬ ì¤‘...")
    
    rows = []
    # íƒ€ê²Ÿë³„ í•„ìˆ˜ ì»¬ëŸ¼ ì„¤ì •
    required_cols = {"level"}
    if target_mode == "gap":
        required_cols.update(["min_key", "max_key"])
    elif target_mode == "kd":
        required_cols.update(["min_key", "max_key", "entry_n"])
    elif target_mode == "entry":
        required_cols.add("entry_n")

    for csv_path in files:
        try:
            df = pd.read_csv(csv_path)
            if not required_cols.issubset(df.columns): continue

            df["level"] = pd.to_numeric(df["level"], errors="coerce")
            df = df.dropna(subset=["level"])
            db_name = csv_path.stem

            for lvl, g in df.groupby("level"):
                if target_mode == "gap":
                    values = compute_level_gaps(g)
                elif target_mode == "kd":
                    values = compute_key_density(g)
                elif target_mode == "entry":
                    values = compute_entry_counts(g)
                else:
                    values = np.array([])

                if values.size > 0:
                    for val in values:
                        rows.append({"db": db_name, "level": int(lvl), "value": float(val)})
        except: continue

    if not rows: raise ValueError("ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨ (CSV ì»¬ëŸ¼ëª… í™•ì¸ í•„ìš”)")
    out = pd.DataFrame(rows)
    logger.info(f"ì´ {len(out)}ê°œ ìƒ˜í”Œ í¬ì¸íŠ¸ ì¶”ì¶œ ì™„ë£Œ.")
    return out


# -----------------------------------------------------------------------------
# 3. ëª¨ë¸ í”¼íŒ… ë° ì ìˆ˜ ê³„ì‚° (Fitting Engine)
# -----------------------------------------------------------------------------

def fit_best_distribution_mle(x: np.ndarray, top_k: int = 1) -> List[Dict[str, Any]]:
    x_safe = ensure_positive(x)
    if len(x_safe) < 20: return [] # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ìŠ¤í‚µ

    candidate_dists = [
        "beta",
        "expon",        # ì§€ìˆ˜ ë¶„í¬
        "lognorm",      # ë¡œê·¸ ì •ê·œ ë¶„í¬
        "skewnorm",     
        "gamma",        # ê°ë§ˆ ë¶„í¬
        "weibull_min",  # ì™€ì´ë¸” ë¶„í¬
        "weibull_max",
        "pareto",       # íŒŒë ˆí†  ë¶„í¬
        "fisk",         # ë¡œê·¸-ë¡œì§€ìŠ¤í‹± ë¶„í¬
        "uniform"       # ê· ë“± ë¶„í¬
    ]    
    results = []
    
    # 1. Scipy Distributions Fitting
    for dist_name in candidate_dists:
        try:
            dist = getattr(st, dist_name)
            params = dist.fit(x_safe, floc=0)
            log_lik = np.sum(dist.logpdf(x_safe, *params))
            if not np.isfinite(log_lik): continue
            bic = -2 * log_lik + len(params) * np.log(len(x_safe))
            D_stat, p_value = kstest(x_safe, dist_name, args=params)
            score = calculate_fitting_score(x_safe, dist_name, params)
            results.append({
                "dist": dist_name, "bic": bic, "params": params,
                "ks_stat": D_stat, "ks_p": p_value, "score": score
            })
        except: continue

    # 2. GMM (Gaussian Mixture Model) Fitting
    for n_comp in [2, 3]:
        try:
            x_reshaped = x_safe.reshape(-1, 1)
            gmm = GaussianMixture(n_components=n_comp, random_state=42)
            gmm.fit(x_reshaped)
            bic = gmm.bic(x_reshaped)
            
            # GMM CDF for Score Calculation
            x_sorted = np.sort(x_safe)
            y_empirical = np.arange(1, len(x_safe) + 1) / len(x_safe)
            y_theoretical = np.zeros_like(x_sorted)
            for w, m, v in zip(gmm.weights_, gmm.means_.flatten(), gmm.covariances_.flatten()):
                y_theoretical += w * norm.cdf(x_sorted, loc=m, scale=np.sqrt(v))
            
            ss_res = np.sum((y_empirical - y_theoretical) ** 2)
            ss_tot = np.sum((y_empirical - np.mean(y_empirical)) ** 2)
            score = max(1 - (ss_res / ss_tot), 0.0) * 100.0 if ss_tot > 0 else 0.0

            results.append({
                "dist": f"gmm_{n_comp}",
                "bic": bic,
                "params": (gmm.weights_.tolist(), gmm.means_.flatten().tolist(), np.sqrt(gmm.covariances_.flatten()).tolist()),
                "ks_stat": np.nan, "ks_p": np.nan, "score": score
            })
        except: continue

    # BICê°€ ë‚®ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬ (ê°€ì¥ ì í•©í•œ ëª¨ë¸ì´ 0ë²ˆ ì¸ë±ìŠ¤)
    results.sort(key=lambda r: r["bic"])
    return results[:top_k]


# -----------------------------------------------------------------------------
# 4. ì‹¤í–‰ ë° ìš”ì•½ ë¦¬í¬íŠ¸
# -----------------------------------------------------------------------------

def run_analysis(df: pd.DataFrame, top_k: int = 3) -> pd.DataFrame:
    summary_rows = []
    
    # DBë³„, Levelë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë¶„ì„ ìˆ˜í–‰
    for (db, lvl), group_df in df.groupby(["db", "level"], sort=True):
        x = group_df["value"].to_numpy(dtype=float)
        row = {"db": db, "level": int(lvl), "sample_count": len(x)}

        if len(x) < 30:
            summary_rows.append(row)
            continue

        # í”¼íŒ… ìˆ˜í–‰
        mle_results = fit_best_distribution_mle(x, top_k=top_k)
        
        for i, res in enumerate(mle_results):
            prefix = f"top_{i+1}"
            row[prefix] = res["dist"]
            row[f"{prefix}_bic"] = round(res["bic"], 2)
            
            # íŒŒë¼ë¯¸í„° ì €ì¥ (GMMê³¼ ì¼ë°˜ ë¶„í¬ êµ¬ë¶„ ì²˜ë¦¬)
            params = res["params"]
            if "gmm" in res["dist"]:
                # Gmm params: (weights, means, stds)
                row[f"{prefix}_params"] = str(params)
            else:
                row[f"{prefix}_params"] = str(tuple(round(float(p), 6) for p in params))
            
            # [Score ì €ì¥] ì†Œìˆ˜ì  2ìë¦¬ê¹Œì§€
            row[f"{prefix}_score"] = round(res["score"], 2)

        summary_rows.append(row)

    return pd.DataFrame(summary_rows)


def print_distribution_stats(df: pd.DataFrame, target_mode: str):
    """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    if "top_1" not in df.columns: return
    valid_df = df.dropna(subset=["top_1"])
    total = len(valid_df)
    if total == 0: return

    print("\n" + "="*60)
    print(f"  ğŸ“Š  [{target_mode.upper()}] Best Distribution Summary (Total: {total})")
    print("="*60)

    print("\n[ğŸ¯ Best Model Counts]")
    for name, count in valid_df["top_1"].value_counts().items():
        print(f"  â€¢ {name:<15} : {(count/total)*100:5.1f}%  ({count} cases)")

    # Score í†µê³„ ì¶œë ¥
    if "top_1_score" in valid_df.columns:
        scores = valid_df["top_1_score"]
        avg_score = scores.mean()
        high_score_ratio = (len(scores[scores >= 90]) / total) * 100
        mid_score_ratio = (len(scores[(scores >= 70) & (scores < 90)]) / total) * 100
        
        print("\n[â­ Goodness-of-Fit Score (0~100)]")
        print(f"  â€¢ Average Score    : {avg_score:.2f}ì ")
        print(f"  â€¢ Excellent (90+)  : {high_score_ratio:.1f}%")
        print(f"  â€¢ Good (70~90)     : {mid_score_ratio:.1f}%")
        print(f"    (ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ëª¨ë¸ì´ ì‹¤ì œ ë°ì´í„° ë¶„í¬ë¥¼ ì™„ë²½í•˜ê²Œ ì„¤ëª…í•¨)")

    print("="*60 + "\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Analyze SSTable distributions with Fitting Score.")
    parser.add_argument("input_dir", help="Directory containing CSV files")
    parser.add_argument("--pattern", default="*.csv", help="File pattern (default: *.csv)")
    parser.add_argument("--output", default=None, help="Output CSV filename")
    parser.add_argument("--target", choices=["gap", "kd", "entry"], default="gap", 
                        help="Analysis target: 'gap' (Gaps), 'kd' (Key Density), 'entry' (Entry Count)")
    
    args = parser.parse_args()

    if args.output is None:
        args.output = f"model_summary_{args.target}.csv"

    try:
        # 1. Load Data
        df_data = build_samples_from_dir(args.input_dir, args.pattern, args.target)
        
        # 2. Run Analysis
        logger.info(f"[{args.target.upper()}] Calculating Best Fit & Scores...")
        summary = run_analysis(df_data)
        
        # 3. Save & Print
        summary.to_csv(args.output, index=False)
        logger.info(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {args.output}")
        print_distribution_stats(summary, args.target)
        
    except Exception as e:
        logger.error(f"Error: {str(e)}")