import argparse
import logging
import numpy as np
import pandas as pd
import scipy.stats as st
from pathlib import Path
from scipy.stats import kstest
from typing import Dict, Any, List, Tuple, Optional
import warnings

# ê²½ê³  ë©”ì‹œì§€ í•„í„°ë§ (ë¶ˆí•„ìš”í•œ RuntimeWarning ìˆ¨ê¹€)
warnings.filterwarnings('ignore')

# -----------------------------------------------------------------------------
# ë¡œê¹… ì„¤ì •
# -----------------------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="[%(levelname)s] %(message)s"
)
logger = logging.getLogger(__name__)


# -----------------------------------------------------------------------------
# 1. ë°ì´í„° ìœ í‹¸ë¦¬í‹° & ì ìˆ˜ ê³„ì‚° (Data Utils & Scoring)
# -----------------------------------------------------------------------------

def ensure_positive(x: np.ndarray, eps: float = 1e-9) -> np.ndarray:
    """ë°ì´í„° ì–‘ìˆ˜ ë³´ì • (ë¡œê·¸ ë¶„í¬ í”¼íŒ… ì‹œ ì—ëŸ¬ ë°©ì§€)"""
    x = np.asarray(x, dtype=float)
    x = x[x >= 0]
    return np.maximum(x, eps)

def calculate_fitting_score(data: np.ndarray, dist_name: str, params: tuple) -> float:
    """
    [í•µì‹¬ ê¸°ëŠ¥] ëª¨ë¸ ì í•©ë„ ì ìˆ˜ ê³„ì‚° (R-squared of CDF)
    
    * ì„¤ëª…: sklearn.metrics.r2_scoreì™€ ìˆ˜í•™ì ìœ¼ë¡œ ë™ì¼í•œ ë¡œì§ì…ë‹ˆë‹¤.
    * ë¦¬í„´: 0 ~ 100 ì‚¬ì´ì˜ ì ìˆ˜ (100ì ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì™„ë²½í•˜ê²Œ ì¼ì¹˜í•¨)
    """
    n = len(data)
    if n < 2: return 0.0
    
    # 1. Empirical CDF (ì‹¤ì œ ë°ì´í„°ì˜ ë¶„í¬)
    # ë°ì´í„°ë¥¼ ì •ë ¬í•˜ì—¬ ê° í¬ì¸íŠ¸ê°€ ì „ì²´ì˜ ëª‡ % ìœ„ì¹˜ì— ìˆëŠ”ì§€ ê³„ì‚°
    x_sorted = np.sort(data)
    y_empirical = np.arange(1, n + 1) / n
    
    # 2. Theoretical CDF (ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ë¶„í¬)
    # ê°™ì€ ë°ì´í„° ê°’(x)ì„ ë„£ì—ˆì„ ë•Œ ëª¨ë¸ì€ ëª‡ % ìœ„ì¹˜ë¼ê³  ì˜ˆì¸¡í•˜ëŠ”ì§€ ê³„ì‚°
    dist = getattr(st, dist_name)
    y_theoretical = dist.cdf(x_sorted, *params)
    
    # 3. R-squared ê³„ì‚° (1 - ì”ì°¨ì œê³±í•© / ì´ì œê³±í•©)
    ss_res = np.sum((y_empirical - y_theoretical) ** 2)
    ss_tot = np.sum((y_empirical - np.mean(y_empirical)) ** 2)
    
    if ss_tot == 0: return 0.0
    
    r2 = 1 - (ss_res / ss_tot)
    
    # ìŒìˆ˜ê°€ ë‚˜ì˜¤ë©´(ëª¨ë¸ì´ í‰ê· ë³´ë‹¤ ëª»í•˜ë©´) 0ì ìœ¼ë¡œ ì²˜ë¦¬, ë°±ë¶„ìœ¨ ë³€í™˜
    final_score = max(r2, 0.0) * 100.0
    return final_score


# -----------------------------------------------------------------------------
# 2. ë°ì´í„° ì¶”ì¶œ ë° ê³„ì‚° ë¡œì§ (SSTable Gap / Key Density)
# -----------------------------------------------------------------------------

def compute_level_gaps(level_df: pd.DataFrame) -> np.ndarray:
    """SSTable ê°„ Gap ê³„ì‚°"""
    sub = level_df.copy()
    sub["min_key"] = pd.to_numeric(sub.get("min_key"), errors="coerce")
    sub["max_key"] = pd.to_numeric(sub.get("max_key"), errors="coerce")
    
    sub = sub.dropna(subset=["min_key", "max_key"])
    if len(sub) < 2: return np.asarray([], dtype=float)

    sub = sub.sort_values(["min_key", "max_key"], kind="mergesort")
    prev_max = sub["max_key"].to_numpy(dtype=float)[:-1]
    next_min = sub["min_key"].to_numpy(dtype=float)[1:]
    
    gaps = next_min - prev_max
    return np.maximum(gaps, 0.0)


def compute_key_density(level_df: pd.DataFrame) -> np.ndarray:
    """SSTable Key Density ê³„ì‚°"""
    sub = level_df.copy()
    cols = ["min_key", "max_key", "entry_n"]
    for c in cols:
        sub[c] = pd.to_numeric(sub.get(c), errors="coerce")

    sub = sub.dropna(subset=cols)
    sub = sub[sub["entry_n"] > 0] 
    
    if len(sub) == 0: return np.asarray([], dtype=float)

    key_range = (sub["max_key"].to_numpy(dtype=float) - sub["min_key"].to_numpy(dtype=float) + 1.0)
    entry_n = sub["entry_n"].to_numpy(dtype=float)

    kd = key_range / entry_n
    
    kd = kd[np.isfinite(kd)]
    kd = kd[kd >= 0]
    return kd.astype(float, copy=False)


def build_samples_from_dir(input_dir: str, pattern: str, target_mode: str) -> pd.DataFrame:
    """CSV íŒŒì¼ë“¤ë¡œë¶€í„° ë¶„ì„ ëŒ€ìƒ ë°ì´í„° ì¶”ì¶œ"""
    in_dir = Path(input_dir)
    files = sorted(in_dir.glob(pattern))
    if not files: raise ValueError(f"íŒŒì¼ ì—†ìŒ: {in_dir}/{pattern}")

    logger.info(f"Target Mode: {target_mode.upper()}")
    logger.info(f"{len(files)}ê°œì˜ íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬ ì¤‘...")
    
    rows = []
    required_cols = {"level", "min_key", "max_key"}
    if target_mode == "kd":
        required_cols.add("entry_n")

    for csv_path in files:
        try:
            df = pd.read_csv(csv_path)
            if not required_cols.issubset(df.columns): continue

            df["level"] = pd.to_numeric(df["level"], errors="coerce")
            df = df.dropna(subset=["level"])
            db_name = csv_path.stem

            for lvl, g in df.groupby("level"):
                if target_mode == "gap":
                    values = compute_level_gaps(g)
                elif target_mode == "kd":
                    values = compute_key_density(g)
                else:
                    values = np.array([])

                if values.size > 0:
                    for val in values:
                        rows.append({"db": db_name, "level": int(lvl), "value": float(val)})
        except: continue

    if not rows: raise ValueError("ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨ (CSV ì»¬ëŸ¼ëª… í™•ì¸ í•„ìš”)")
    out = pd.DataFrame(rows)
    logger.info(f"ì´ {len(out)}ê°œ ìƒ˜í”Œ í¬ì¸íŠ¸ ì¶”ì¶œ ì™„ë£Œ.")
    return out


# -----------------------------------------------------------------------------
# 3. ëª¨ë¸ í”¼íŒ… ë° ì ìˆ˜ ê³„ì‚° (Fitting Engine)
# -----------------------------------------------------------------------------

def fit_best_distribution_mle(x: np.ndarray, top_k: int = 1) -> List[Dict[str, Any]]:
    x_safe = ensure_positive(x)
    if len(x_safe) < 20: return [] # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ìŠ¤í‚µ

    candidate_dists = [
        "expon",        # ì§€ìˆ˜ ë¶„í¬
        "lognorm",      # ë¡œê·¸ ì •ê·œ ë¶„í¬
        "gamma",        # ê°ë§ˆ ë¶„í¬
        "weibull_min",  # ì™€ì´ë¸” ë¶„í¬
        "pareto",       # íŒŒë ˆí†  ë¶„í¬
        "fisk",         # ë¡œê·¸-ë¡œì§€ìŠ¤í‹± ë¶„í¬
        "uniform"       # ê· ë“± ë¶„í¬
    ]    
    results = []
    
    for dist_name in candidate_dists:
        try:
            dist = getattr(st, dist_name)
            
            # 1. Fit (MLE: ìµœëŒ€ìš°ë„ì¶”ì •)
            params = dist.fit(x_safe, floc=0)
            
            # 2. BIC ê³„ì‚° (ëª¨ë¸ ì„ íƒ ê¸°ì¤€)
            log_lik = np.sum(dist.logpdf(x_safe, *params))
            if not np.isfinite(log_lik): continue
            bic =  - 2 * log_lik

            # 3. K-S Test (ì°¸ê³ ìš© í†µê³„)
            D_stat, p_value = kstest(x_safe, dist_name, args=params)
            
            # 4. Score ê³„ì‚° (0~100ì ) - ì§ê´€ì  ì§€í‘œ
            score = calculate_fitting_score(x_safe, dist_name, params)

            results.append({
                "dist": dist_name, 
                "bic": bic, 
                "params": params,
                "ks_stat": D_stat,
                "ks_p": p_value,
                "score": score
            })
        except: continue

    # BICê°€ ë‚®ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬ (ê°€ì¥ ì í•©í•œ ëª¨ë¸ì´ 0ë²ˆ ì¸ë±ìŠ¤)
    results.sort(key=lambda r: r["bic"])
    return results[:top_k]


# -----------------------------------------------------------------------------
# 4. ì‹¤í–‰ ë° ìš”ì•½ ë¦¬í¬íŠ¸
# -----------------------------------------------------------------------------

def run_analysis(df: pd.DataFrame, top_k: int = 3) -> pd.DataFrame:
    summary_rows = []
    
    # DBë³„, Levelë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë¶„ì„ ìˆ˜í–‰
    for (db, lvl), group_df in df.groupby(["db", "level"], sort=True):
        x = group_df["value"].to_numpy(dtype=float)
        row = {"db": db, "level": int(lvl), "sample_count": len(x)}

        if len(x) < 30:
            summary_rows.append(row)
            continue

        # í”¼íŒ… ìˆ˜í–‰
        mle_results = fit_best_distribution_mle(x, top_k=top_k)
        
        for i, res in enumerate(mle_results):
            prefix = f"top_{i+1}"
            row[prefix] = res["dist"]
            row[f"{prefix}_bic"] = round(res["bic"], 2)
            # row[f"{prefix}_params"] = str(tuple(round(p, 6) for p in res["params"]))
            # row[f"{prefix}_ks"] = round(res["ks_stat"], 4)
            # row[f"{prefix}_p"] = round(res["ks_p"], 6)
            
            # [Score ì €ì¥] ì†Œìˆ˜ì  2ìë¦¬ê¹Œì§€
            # row[f"{prefix}_score"] = round(res["score"], 2)

        summary_rows.append(row)

    return pd.DataFrame(summary_rows)


def print_distribution_stats(df: pd.DataFrame, target_mode: str):
    """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    if "best_dist_1" not in df.columns: return
    valid_df = df.dropna(subset=["best_dist_1"])
    total = len(valid_df)
    if total == 0: return

    print("\n" + "="*60)
    print(f"  ğŸ“Š  [{target_mode.upper()}] Best Distribution Summary (Total: {total})")
    print("="*60)

    print("\n[ğŸ¯ Best Model Counts]")
    for name, count in valid_df["best_dist_1"].value_counts().items():
        print(f"  â€¢ {name:<15} : {(count/total)*100:5.1f}%  ({count} cases)")

    # Score í†µê³„ ì¶œë ¥
    if "best_dist_1_score" in valid_df.columns:
        scores = valid_df["best_dist_1_score"]
        avg_score = scores.mean()
        high_score_ratio = (len(scores[scores >= 90]) / total) * 100
        mid_score_ratio = (len(scores[(scores >= 70) & (scores < 90)]) / total) * 100
        
        print("\n[â­ Goodness-of-Fit Score (0~100)]")
        print(f"  â€¢ Average Score    : {avg_score:.2f}ì ")
        print(f"  â€¢ Excellent (90+)  : {high_score_ratio:.1f}%")
        print(f"  â€¢ Good (70~90)     : {mid_score_ratio:.1f}%")
        print(f"    (ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ëª¨ë¸ì´ ì‹¤ì œ ë°ì´í„° ë¶„í¬ë¥¼ ì™„ë²½í•˜ê²Œ ì„¤ëª…í•¨)")

    print("="*60 + "\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Analyze SSTable distributions with Fitting Score.")
    parser.add_argument("input_dir", help="Directory containing CSV files")
    parser.add_argument("--pattern", default="*.csv", help="File pattern (default: *.csv)")
    parser.add_argument("--output", default=None, help="Output CSV filename")
    parser.add_argument("--target", choices=["gap", "kd"], default="gap", 
                        help="Analysis target: 'gap' (Gaps) or 'kd' (Key Density)")
    
    args = parser.parse_args()

    if args.output is None:
        args.output = f"model_summary_{args.target}.csv"

    try:
        # 1. Load Data
        df_data = build_samples_from_dir(args.input_dir, args.pattern, args.target)
        
        # 2. Run Analysis
        logger.info(f"[{args.target.upper()}] Calculating Best Fit & Scores...")
        summary = run_analysis(df_data)
        
        # 3. Save & Print
        summary.to_csv(args.output, index=False)
        logger.info(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {args.output}")
        print_distribution_stats(summary, args.target)
        
    except Exception as e:
        logger.error(f"Error: {str(e)}")